{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4969612,"sourceType":"datasetVersion","datasetId":2882322}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nfrom torchvision.models import resnet18, ResNet18_Weights\nimport torch\nimport PIL","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:55:57.445184Z","iopub.execute_input":"2024-12-06T18:55:57.445542Z","iopub.status.idle":"2024-12-06T18:56:03.108233Z","shell.execute_reply.started":"2024-12-06T18:55:57.445508Z","shell.execute_reply":"2024-12-06T18:56:03.107538Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\n\nDATASET_PATH = '/kaggle/input/dog-emotion/Dog Emotion/'\n\ndata = {'img': [], 'emotion': []}\n\nfor emotion in ['angry', 'happy', 'relaxed', 'sad']:\n    for dirname, _, filenames in os.walk(DATASET_PATH + emotion + '/'):\n        for filename in filenames:\n            data['img'].append(os.path.join(dirname, filename))\n            data['emotion'].append(emotion)\n\ndf = pd.DataFrame.from_dict(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:56:03.113092Z","iopub.execute_input":"2024-12-06T18:56:03.113349Z","iopub.status.idle":"2024-12-06T18:56:10.252074Z","shell.execute_reply.started":"2024-12-06T18:56:03.113321Z","shell.execute_reply":"2024-12-06T18:56:10.251285Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:56:30.659394Z","iopub.execute_input":"2024-12-06T18:56:30.659776Z","iopub.status.idle":"2024-12-06T18:56:30.671022Z","shell.execute_reply.started":"2024-12-06T18:56:30.659743Z","shell.execute_reply":"2024-12-06T18:56:30.670190Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                    img emotion\n0     /kaggle/input/dog-emotion/Dog Emotion/angry/RD...   angry\n1     /kaggle/input/dog-emotion/Dog Emotion/angry/GJ...   angry\n2     /kaggle/input/dog-emotion/Dog Emotion/angry/GX...   angry\n3     /kaggle/input/dog-emotion/Dog Emotion/angry/b3...   angry\n4     /kaggle/input/dog-emotion/Dog Emotion/angry/Hf...   angry\n...                                                 ...     ...\n3995  /kaggle/input/dog-emotion/Dog Emotion/sad/VNqe...     sad\n3996  /kaggle/input/dog-emotion/Dog Emotion/sad/0Bnt...     sad\n3997  /kaggle/input/dog-emotion/Dog Emotion/sad/aWoj...     sad\n3998  /kaggle/input/dog-emotion/Dog Emotion/sad/8ihS...     sad\n3999  /kaggle/input/dog-emotion/Dog Emotion/sad/TBHx...     sad\n\n[4000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/angry/RD...</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/angry/GJ...</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/angry/GX...</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/angry/b3...</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/angry/Hf...</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/sad/VNqe...</td>\n      <td>sad</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/sad/0Bnt...</td>\n      <td>sad</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/sad/aWoj...</td>\n      <td>sad</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/sad/8ihS...</td>\n      <td>sad</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/sad/TBHx...</td>\n      <td>sad</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"emotion_labels_map = {}\n\nunique_emotions = df['emotion'].unique()\nfor i in range(len(unique_emotions)):\n    emotion_labels_map[unique_emotions[i]] = i","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:00:27.076803Z","iopub.execute_input":"2024-12-06T19:00:27.077450Z","iopub.status.idle":"2024-12-06T19:00:27.082425Z","shell.execute_reply.started":"2024-12-06T19:00:27.077415Z","shell.execute_reply":"2024-12-06T19:00:27.081463Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df['emotion_label'] = df['emotion'].apply(lambda x: emotion_labels_map[x])\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:01:03.110209Z","iopub.execute_input":"2024-12-06T19:01:03.110982Z","iopub.status.idle":"2024-12-06T19:01:03.125318Z","shell.execute_reply.started":"2024-12-06T19:01:03.110941Z","shell.execute_reply":"2024-12-06T19:01:03.124391Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                    img emotion  emotion_label\n0     /kaggle/input/dog-emotion/Dog Emotion/angry/RD...   angry              0\n1     /kaggle/input/dog-emotion/Dog Emotion/angry/GJ...   angry              0\n2     /kaggle/input/dog-emotion/Dog Emotion/angry/GX...   angry              0\n3     /kaggle/input/dog-emotion/Dog Emotion/angry/b3...   angry              0\n4     /kaggle/input/dog-emotion/Dog Emotion/angry/Hf...   angry              0\n...                                                 ...     ...            ...\n3995  /kaggle/input/dog-emotion/Dog Emotion/sad/VNqe...     sad              3\n3996  /kaggle/input/dog-emotion/Dog Emotion/sad/0Bnt...     sad              3\n3997  /kaggle/input/dog-emotion/Dog Emotion/sad/aWoj...     sad              3\n3998  /kaggle/input/dog-emotion/Dog Emotion/sad/8ihS...     sad              3\n3999  /kaggle/input/dog-emotion/Dog Emotion/sad/TBHx...     sad              3\n\n[4000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img</th>\n      <th>emotion</th>\n      <th>emotion_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/angry/RD...</td>\n      <td>angry</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/angry/GJ...</td>\n      <td>angry</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/angry/GX...</td>\n      <td>angry</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/angry/b3...</td>\n      <td>angry</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/angry/Hf...</td>\n      <td>angry</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/sad/VNqe...</td>\n      <td>sad</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/sad/0Bnt...</td>\n      <td>sad</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/sad/aWoj...</td>\n      <td>sad</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/sad/8ihS...</td>\n      <td>sad</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>/kaggle/input/dog-emotion/Dog Emotion/sad/TBHx...</td>\n      <td>sad</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n\nclass Dataset(Dataset):\n    def __init__(self, data, transform):\n        self.data = data\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        image = PIL.Image.open(self.data.loc[idx, \"img\"]).convert('RGB')\n        image = self.transform(image)\n        label = torch.tensor(self.data.loc[idx, \"emotion_label\"])\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:08:02.435669Z","iopub.execute_input":"2024-12-06T19:08:02.436597Z","iopub.status.idle":"2024-12-06T19:08:02.441728Z","shell.execute_reply.started":"2024-12-06T19:08:02.436557Z","shell.execute_reply":"2024-12-06T19:08:02.440887Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from torchvision.transforms import v2\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df[\"img\"], df[\"emotion_label\"], random_state=42)\n\nX_train.index = np.arange(len(X_train))\ny_train.index = np.arange(len(y_train))\nX_test.index = np.arange(len(X_test))\ny_test.index = np.arange(len(y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:08:03.944319Z","iopub.execute_input":"2024-12-06T19:08:03.944927Z","iopub.status.idle":"2024-12-06T19:08:03.957068Z","shell.execute_reply.started":"2024-12-06T19:08:03.944880Z","shell.execute_reply":"2024-12-06T19:08:03.956110Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"transform_test = v2.Compose([\n    v2.Resize(size=(224, 224)),\n    v2.PILToTensor(),\n    v2.ToDtype(torch.float32, scale=True),\n    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:08:05.323235Z","iopub.execute_input":"2024-12-06T19:08:05.323590Z","iopub.status.idle":"2024-12-06T19:08:05.328782Z","shell.execute_reply.started":"2024-12-06T19:08:05.323558Z","shell.execute_reply":"2024-12-06T19:08:05.327909Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"train_ds = Dataset(pd.concat([X_train, y_train], axis=1), transform_test)\ntest_ds = Dataset(pd.concat([X_test, y_test], axis=1), transform_test)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, num_workers=4)\ntest_loader = DataLoader(test_ds, batch_size=32, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:08:07.579664Z","iopub.execute_input":"2024-12-06T19:08:07.580001Z","iopub.status.idle":"2024-12-06T19:08:07.588295Z","shell.execute_reply.started":"2024-12-06T19:08:07.579971Z","shell.execute_reply":"2024-12-06T19:08:07.587217Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class Extraction:\n    def __init__(self, network):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.network = network.eval().to(self.device)\n        \n    def extract(self, loader):\n        data_tmp = []\n        label_tmp = []\n\n        with torch.no_grad():\n            for x, y in loader:\n                x = x.to(self.device)\n            \n                outputs = self.network(x)\n                data_tmp.append(outputs.view(-1, 512).cpu().numpy())\n                \n                label_tmp.append(y.cpu().numpy())\n                \n        return np.vstack(data_tmp), np.hstack(label_tmp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:08:08.829006Z","iopub.execute_input":"2024-12-06T19:08:08.829936Z","iopub.status.idle":"2024-12-06T19:08:08.835545Z","shell.execute_reply.started":"2024-12-06T19:08:08.829894Z","shell.execute_reply":"2024-12-06T19:08:08.834589Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"model = resnet18(weights=ResNet18_Weights.DEFAULT)\nfeature_extractor = torch.nn.Sequential(*list(model.children())[:-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:08:11.770362Z","iopub.execute_input":"2024-12-06T19:08:11.770729Z","iopub.status.idle":"2024-12-06T19:08:12.024149Z","shell.execute_reply.started":"2024-12-06T19:08:11.770696Z","shell.execute_reply":"2024-12-06T19:08:12.023167Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"feature_extractor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:08:14.855769Z","iopub.execute_input":"2024-12-06T19:08:14.856190Z","iopub.status.idle":"2024-12-06T19:08:14.863076Z","shell.execute_reply.started":"2024-12-06T19:08:14.856154Z","shell.execute_reply":"2024-12-06T19:08:14.862154Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (5): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (6): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (7): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"ext = Extraction(feature_extractor)\n\ntrain_feature, train_label = ext.extract(train_loader)\ntest_feature, test_label = ext.extract(test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:08:17.655131Z","iopub.execute_input":"2024-12-06T19:08:17.655481Z","iopub.status.idle":"2024-12-06T19:08:33.849281Z","shell.execute_reply.started":"2024-12-06T19:08:17.655448Z","shell.execute_reply":"2024-12-06T19:08:33.848252Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\n\nparam = {\n    \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n    #'C': [0.1, 0.5, 1, 2, 5, 10]\n}\n\nsvc = svm.SVC()\nsvm_grid = GridSearchCV(svc, param_grid=param, verbose=2, n_jobs=-1)\n\nsvm_grid.fit(train_feature, train_label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:09:07.324862Z","iopub.execute_input":"2024-12-06T19:09:07.325764Z","iopub.status.idle":"2024-12-06T19:09:26.201246Z","shell.execute_reply.started":"2024-12-06T19:09:07.325725Z","shell.execute_reply":"2024-12-06T19:09:26.200198Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 4 candidates, totalling 20 fits\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(estimator=SVC(), n_jobs=-1,\n             param_grid={'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n             verbose=2)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(), n_jobs=-1,\n             param_grid={&#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(), n_jobs=-1,\n             param_grid={&#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"y_pred_svm_grid = svm_grid.predict(test_feature)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:09:38.258970Z","iopub.execute_input":"2024-12-06T19:09:38.259792Z","iopub.status.idle":"2024-12-06T19:09:38.662473Z","shell.execute_reply.started":"2024-12-06T19:09:38.259753Z","shell.execute_reply":"2024-12-06T19:09:38.661752Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n\naccuracy_score(test_label, y_pred_svm_grid)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:09:57.380491Z","iopub.execute_input":"2024-12-06T19:09:57.381108Z","iopub.status.idle":"2024-12-06T19:09:57.387786Z","shell.execute_reply.started":"2024-12-06T19:09:57.381071Z","shell.execute_reply":"2024-12-06T19:09:57.386894Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0.734"},"metadata":{}},{"name":"stdout","text":"[CV] END ......................................kernel=linear; total time=   3.4s\n[CV] END ........................................kernel=poly; total time=   2.3s\n[CV] END ........................................kernel=poly; total time=   2.8s\n[CV] END .........................................kernel=rbf; total time=   3.1s\n[CV] END .....................................kernel=sigmoid; total time=   2.6s\n[CV] END ......................................kernel=linear; total time=   3.3s\n[CV] END ........................................kernel=poly; total time=   2.9s\n[CV] END ........................................kernel=poly; total time=   3.2s\n[CV] END .........................................kernel=rbf; total time=   3.1s\n[CV] END .....................................kernel=sigmoid; total time=   2.3s\n[CV] END ......................................kernel=linear; total time=   3.1s\n[CV] END ......................................kernel=linear; total time=   4.1s\n[CV] END .........................................kernel=rbf; total time=   3.3s\n[CV] END .....................................kernel=sigmoid; total time=   2.2s\n[CV] END .....................................kernel=sigmoid; total time=   2.2s\n[CV] END ......................................kernel=linear; total time=   3.8s\n[CV] END ........................................kernel=poly; total time=   2.8s\n[CV] END .........................................kernel=rbf; total time=   3.7s\n[CV] END .........................................kernel=rbf; total time=   3.2s\n[CV] END .....................................kernel=sigmoid; total time=   2.1s\n","output_type":"stream"}],"execution_count":29}]}